{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be51478",
   "metadata": {},
   "source": [
    "# Efficient Frontier Project (Updated) — ECO 43000\n",
    "\n",
    "**Student ID:** 23841777  \n",
    "**Instructor:** John Droescher\n",
    "\n",
    "This updated notebook adds a **legend** to the Efficient Frontier chart:\n",
    "- Monte Carlo portfolios\n",
    "- Max Sharpe\n",
    "- Regression frontier\n",
    "\n",
    "It otherwise reproduces the full analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & configuration\n",
    "import os, math\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "OUTPUT_DIR = \"/mnt/data/efficient_frontier_project\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "TICKERS = [\"IBM\", \"JPM\", \"XOM\", \"WMT\", \"JNJ\", \"KO\", \"T\"]\n",
    "RISK_FREE_RATE = 0.04\n",
    "END_DATE = datetime.today()\n",
    "START_DATE = END_DATE - timedelta(days=365*2 + 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c00ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated class with legend in the frontier plot\n",
    "class EfficientFrontierProject:\n",
    "    def __init__(self, tickers, start_date, end_date, rf=0.0, output_dir=\".\"):\n",
    "        self.tickers = tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.rf = rf\n",
    "        self.output_dir = output_dir\n",
    "        self.prices = None\n",
    "        self.returns = None\n",
    "        self.mu = None\n",
    "        self.Sigma = None\n",
    "        self.corr = None\n",
    "        self.mc_results = None\n",
    "        self.opt_weights = None\n",
    "        self.opt_stats = None\n",
    "\n",
    "    def fetch_prices(self):\n",
    "        try:\n",
    "            import yfinance as yf\n",
    "            df = yf.download(self.tickers, start=self.start_date, end=self.end_date, progress=False)[\"Adj Close\"]\n",
    "            if isinstance(df, pd.Series):\n",
    "                df = df.to_frame()\n",
    "            missing = [t for t in self.tickers if t not in df.columns]\n",
    "            if len(df) == 0 or len(missing) > 0:\n",
    "                raise RuntimeError(\"Missing tickers or empty data\")\n",
    "            self.prices = df.dropna()\n",
    "            source = \"downloaded\"\n",
    "        except Exception:\n",
    "            dates = pd.bdate_range(self.start_date, self.end_date)\n",
    "            n = len(dates)\n",
    "            k = len(self.tickers)\n",
    "            annual_mu = np.array([0.08, 0.10, 0.11, 0.07, 0.06, 0.065, 0.055])\n",
    "            annual_sigma = np.array([0.22, 0.24, 0.27, 0.18, 0.16, 0.17, 0.20])\n",
    "            base_corr = 0.25\n",
    "            corr_matrix = np.full((k, k), base_corr) + np.diag([1 - base_corr]*k)\n",
    "            cov = np.outer(annual_sigma, annual_sigma) * corr_matrix\n",
    "            dt = 1/252\n",
    "            chol = np.linalg.cholesky(cov * dt)\n",
    "            prices = np.zeros((n, k))\n",
    "            prices[0, :] = 100.0\n",
    "            for t in range(1, n):\n",
    "                z = np.random.normal(size=k)\n",
    "                dW = chol @ z\n",
    "                drift = (annual_mu - 0.5*annual_sigma**2) * dt\n",
    "                prices[t, :] = prices[t-1, :] * np.exp(drift + dW)\n",
    "            self.prices = pd.DataFrame(prices, index=dates, columns=self.tickers)\n",
    "            source = \"simulated\"\n",
    "        return source\n",
    "\n",
    "    def compute_statistics(self):\n",
    "        ret = np.log(self.prices / self.prices.shift(1)).dropna()\n",
    "        self.returns = ret\n",
    "        self.mu = ret.mean() * 252\n",
    "        self.Sigma = ret.cov() * 252\n",
    "        self.corr = ret.corr()\n",
    "        return self.mu, self.Sigma, self.corr\n",
    "\n",
    "    def monte_carlo(self, n_portfolios=50000):\n",
    "        n = len(self.tickers)\n",
    "        means, stds, sharpes, weights_list = [], [], [], []\n",
    "        Sigma = self.Sigma.values\n",
    "        mu = self.mu.values\n",
    "        for _ in range(n_portfolios):\n",
    "            w = np.random.dirichlet(np.ones(n))\n",
    "            port_mu = np.dot(w, mu)\n",
    "            port_var = np.dot(w, Sigma @ w)\n",
    "            port_std = np.sqrt(port_var)\n",
    "            sharpe = (port_mu - self.rf) / port_std if port_std > 0 else -np.inf\n",
    "            means.append(port_mu); stds.append(port_std); sharpes.append(sharpe); weights_list.append(w)\n",
    "        df = pd.DataFrame({\"Return\": means, \"Volatility\": stds, \"Sharpe\": sharpes})\n",
    "        for i, t in enumerate(self.tickers):\n",
    "            df[t] = [w[i] for w in weights_list]\n",
    "        self.mc_results = df\n",
    "        idx = df[\"Sharpe\"].idxmax()\n",
    "        self.opt_weights = df.loc[idx, self.tickers].values\n",
    "        self.opt_stats = {\n",
    "            \"Return\": df.loc[idx, \"Return\"],\n",
    "            \"Volatility\": df.loc[idx, \"Volatility\"],\n",
    "            \"Sharpe\": df.loc[idx, \"Sharpe\"]\n",
    "        }\n",
    "        return self.mc_results, self.opt_weights, self.opt_stats\n",
    "\n",
    "    def regression_frontier(self, bins=60, degree=2):\n",
    "        df = self.mc_results.copy()\n",
    "        vol = df[\"Volatility\"].values.reshape(-1, 1)\n",
    "        ret = df[\"Return\"].values\n",
    "        vmin, vmax = vol.min(), vol.max()\n",
    "        edges = np.linspace(vmin, vmax, bins+1)\n",
    "        centers = 0.5*(edges[:-1] + edges[1:])\n",
    "        max_ret, valid_centers = [], []\n",
    "        for i in range(bins):\n",
    "            mask = (vol.flatten() >= edges[i]) & (vol.flatten() < edges[i+1])\n",
    "            if mask.sum() > 0:\n",
    "                max_ret.append(ret[mask].max())\n",
    "                valid_centers.append(centers[i])\n",
    "        X = np.array(valid_centers).reshape(-1, 1)\n",
    "        y = np.array(max_ret)\n",
    "        poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "        model = LinearRegression().fit(X_poly, y)\n",
    "        vol_curve = np.linspace(vmin, vmax, 400).reshape(-1, 1)\n",
    "        vol_curve_poly = poly.transform(vol_curve)\n",
    "        ret_curve = model.predict(vol_curve_poly)\n",
    "        reg_data = pd.DataFrame({\"Volatility\": vol_curve.flatten(), \"Return\": ret_curve})\n",
    "        return model, reg_data\n",
    "\n",
    "    def plot_correlation_matrix(self, save=True, filename=\"correlation_matrix_updated.png\"):\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        cax = ax.imshow(self.corr.values, interpolation='nearest')\n",
    "        ax.set_xticks(range(len(self.tickers)))\n",
    "        ax.set_yticks(range(len(self.tickers)))\n",
    "        ax.set_xticklabels(self.tickers, rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels(self.tickers)\n",
    "        fig.colorbar(cax)\n",
    "        ax.set_title(\"Correlation Matrix\")\n",
    "        fig.tight_layout()\n",
    "        path = None\n",
    "        if save:\n",
    "            path = os.path.join(self.output_dir, filename)\n",
    "            fig.savefig(path, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        return path\n",
    "\n",
    "    def plot_frontier(self, reg_data=None, save=True, filename=\"efficient_frontier_updated.png\"):\n",
    "        fig, ax = plt.subplots(figsize=(7, 5))\n",
    "        ax.scatter(self.mc_results[\"Volatility\"], self.mc_results[\"Return\"], s=3, alpha=0.4, label=\"Monte Carlo portfolios\")\n",
    "        ow = self.opt_stats\n",
    "        ax.scatter([ow[\"Volatility\"]], [ow[\"Return\"]], marker=\"*\", s=180, label=\"Max Sharpe\")\n",
    "        if reg_data is not None:\n",
    "            ax.plot(reg_data[\"Volatility\"], reg_data[\"Return\"], linewidth=2, label=\"Regression frontier\")\n",
    "        ax.set_xlabel(\"σ (Volatility)\")\n",
    "        ax.set_ylabel(\"E(R) (Annual Return)\")\n",
    "        ax.set_title(\"Efficient Frontier (Monte Carlo + Regression)\")\n",
    "        ax.legend(loc=\"best\")\n",
    "        fig.tight_layout()\n",
    "        path = None\n",
    "        if save:\n",
    "            path = os.path.join(self.output_dir, filename)\n",
    "            fig.savefig(path, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff04cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executed updated pipeline and regenerate charts\n",
    "proj = EfficientFrontierProject(TICKERS, START_DATE, END_DATE, rf=RISK_FREE_RATE, output_dir=OUTPUT_DIR)\n",
    "src = proj.fetch_prices()\n",
    "mu, Sigma, corr = proj.compute_statistics()\n",
    "mc_df, opt_w, opt_stats = proj.monte_carlo(n_portfolios=50000)\n",
    "model, reg_data = proj.regression_frontier(bins=60, degree=2)\n",
    "\n",
    "cm_path = proj.plot_correlation_matrix(save=True, filename=\"correlation_matrix_updated.png\")\n",
    "ef_path = proj.plot_frontier(reg_data=reg_data, save=True, filename=\"efficient_frontier_updated.png\")\n",
    "\n",
    "cm_path, ef_path, src, opt_stats\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
