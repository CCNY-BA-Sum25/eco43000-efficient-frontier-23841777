{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5c3476",
   "metadata": {},
   "source": [
    "# Efficient Frontier Project — ECO 43000 (Student ID: 23841777)\n",
    "\n",
    "This notebook reproduces the full analysis required by the assignment:\n",
    "- Select 7 NYSE assets\n",
    "- Pull 2 years of daily prices (via `yfinance`) — if unavailable, simulate realistic data\n",
    "- Compute mean returns, covariance, and correlation\n",
    "- Monte Carlo portfolios to find **max Sharpe**\n",
    "- **Regression** fit for the efficient frontier boundary\n",
    "- Save charts and outputs for submission\n",
    "\n",
    "> Instructor: John Droescher  \n",
    "> Repo: `efficient-frontier-quant-finance-23841777`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & global configuration\n",
    "import os, math\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Output folder\n",
    "OUTPUT_DIR = \"/mnt/data/efficient_frontier_project\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Project config\n",
    "TICKERS = [\"IBM\", \"JPM\", \"XOM\", \"WMT\", \"JNJ\", \"KO\", \"T\"]  # NYSE tickers\n",
    "RISK_FREE_RATE = 0.04  # 4%\n",
    "END_DATE = datetime.today()\n",
    "START_DATE = END_DATE - timedelta(days=365*2 + 5)\n",
    "\n",
    "# Matplotlib note: no custom styles/colors per assignment constraints here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aaffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core class encapsulating the workflow\n",
    "class EfficientFrontierProject:\n",
    "    def __init__(self, tickers, start_date, end_date, rf=0.0, output_dir=\".\"):\n",
    "        self.tickers = tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.rf = rf\n",
    "        self.output_dir = output_dir\n",
    "        self.prices = None\n",
    "        self.returns = None\n",
    "        self.mu = None\n",
    "        self.Sigma = None\n",
    "        self.corr = None\n",
    "        self.mc_results = None\n",
    "        self.opt_weights = None\n",
    "        self.opt_stats = None\n",
    "\n",
    "    def fetch_prices(self):\n",
    "        \"\"\"Attempt to fetch prices using yfinance; otherwise simulate GBM-like data.\"\"\"\n",
    "        try:\n",
    "            import yfinance as yf\n",
    "            df = yf.download(self.tickers, start=self.start_date, end=self.end_date, progress=False)[\"Adj Close\"]\n",
    "            if isinstance(df, pd.Series):\n",
    "                df = df.to_frame()\n",
    "            missing = [t for t in self.tickers if t not in df.columns]\n",
    "            if len(df) == 0 or len(missing) > 0:\n",
    "                raise RuntimeError(\"Missing tickers or empty data\")\n",
    "            self.prices = df.dropna()\n",
    "            source = \"downloaded\"\n",
    "        except Exception:\n",
    "            dates = pd.bdate_range(self.start_date, self.end_date)\n",
    "            n = len(dates)\n",
    "            k = len(self.tickers)\n",
    "            annual_mu = np.array([0.08, 0.10, 0.11, 0.07, 0.06, 0.065, 0.055])\n",
    "            annual_sigma = np.array([0.22, 0.24, 0.27, 0.18, 0.16, 0.17, 0.20])\n",
    "            base_corr = 0.25\n",
    "            corr_matrix = np.full((k, k), base_corr) + np.diag([1 - base_corr]*k)\n",
    "            cov = np.outer(annual_sigma, annual_sigma) * corr_matrix\n",
    "            dt = 1/252\n",
    "            chol = np.linalg.cholesky(cov * dt)\n",
    "            prices = np.zeros((n, k))\n",
    "            prices[0, :] = 100.0\n",
    "            for t in range(1, n):\n",
    "                z = np.random.normal(size=k)\n",
    "                dW = chol @ z\n",
    "                drift = (annual_mu - 0.5*annual_sigma**2) * dt\n",
    "                prices[t, :] = prices[t-1, :] * np.exp(drift + dW)\n",
    "            self.prices = pd.DataFrame(prices, index=dates, columns=self.tickers)\n",
    "            source = \"simulated\"\n",
    "        return source\n",
    "\n",
    "    def compute_statistics(self):\n",
    "        ret = np.log(self.prices / self.prices.shift(1)).dropna()\n",
    "        self.returns = ret\n",
    "        self.mu = ret.mean() * 252\n",
    "        self.Sigma = ret.cov() * 252\n",
    "        self.corr = ret.corr()\n",
    "        return self.mu, self.Sigma, self.corr\n",
    "\n",
    "    def monte_carlo(self, n_portfolios=50000):\n",
    "        n = len(self.tickers)\n",
    "        means, stds, sharpes, weights_list = [], [], [], []\n",
    "        Sigma = self.Sigma.values\n",
    "        mu = self.mu.values\n",
    "        for _ in range(n_portfolios):\n",
    "            w = np.random.dirichlet(np.ones(n))\n",
    "            port_mu = np.dot(w, mu)\n",
    "            port_var = np.dot(w, Sigma @ w)\n",
    "            port_std = math.sqrt(port_var)\n",
    "            sharpe = (port_mu - self.rf) / port_std if port_std > 0 else -np.inf\n",
    "            means.append(port_mu); stds.append(port_std); sharpes.append(sharpe); weights_list.append(w)\n",
    "        df = pd.DataFrame({\"Return\": means, \"Volatility\": stds, \"Sharpe\": sharpes})\n",
    "        for i, t in enumerate(self.tickers):\n",
    "            df[t] = [w[i] for w in weights_list]\n",
    "        self.mc_results = df\n",
    "        idx = df[\"Sharpe\"].idxmax()\n",
    "        self.opt_weights = df.loc[idx, self.tickers].values\n",
    "        self.opt_stats = {\n",
    "            \"Return\": df.loc[idx, \"Return\"],\n",
    "            \"Volatility\": df.loc[idx, \"Volatility\"],\n",
    "            \"Sharpe\": df.loc[idx, \"Sharpe\"]\n",
    "        }\n",
    "        return self.mc_results, self.opt_weights, self.opt_stats\n",
    "\n",
    "    def regression_frontier(self, bins=60, degree=2):\n",
    "        df = self.mc_results.copy()\n",
    "        vol = df[\"Volatility\"].values.reshape(-1, 1)\n",
    "        ret = df[\"Return\"].values\n",
    "        vmin, vmax = vol.min(), vol.max()\n",
    "        edges = np.linspace(vmin, vmax, bins+1)\n",
    "        centers = 0.5*(edges[:-1] + edges[1:])\n",
    "        max_ret, valid_centers = [], []\n",
    "        for i in range(bins):\n",
    "            mask = (vol.flatten() >= edges[i]) & (vol.flatten() < edges[i+1])\n",
    "            if mask.sum() > 0:\n",
    "                max_ret.append(ret[mask].max())\n",
    "                valid_centers.append(centers[i])\n",
    "        X = np.array(valid_centers).reshape(-1, 1)\n",
    "        y = np.array(max_ret)\n",
    "        poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "        model = LinearRegression().fit(X_poly, y)\n",
    "        vol_curve = np.linspace(vmin, vmax, 400).reshape(-1, 1)\n",
    "        vol_curve_poly = poly.transform(vol_curve)\n",
    "        ret_curve = model.predict(vol_curve_poly)\n",
    "        reg_data = pd.DataFrame({\"Volatility\": vol_curve.flatten(), \"Return\": ret_curve})\n",
    "        return model, reg_data\n",
    "\n",
    "    def plot_correlation_matrix(self, save=True):\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        cax = ax.imshow(self.corr.values, interpolation='nearest')\n",
    "        ax.set_xticks(range(len(self.tickers)))\n",
    "        ax.set_yticks(range(len(self.tickers)))\n",
    "        ax.set_xticklabels(self.tickers, rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels(self.tickers)\n",
    "        fig.colorbar(cax)\n",
    "        ax.set_title(\"Correlation Matrix\")\n",
    "        fig.tight_layout()\n",
    "        path = None\n",
    "        if save:\n",
    "            path = os.path.join(self.output_dir, \"correlation_matrix.png\")\n",
    "            fig.savefig(path, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        return path\n",
    "\n",
    "    def plot_frontier(self, reg_data=None, save=True):\n",
    "        fig, ax = plt.subplots(figsize=(7, 5))\n",
    "        ax.scatter(self.mc_results[\"Volatility\"], self.mc_results[\"Return\"], s=3, alpha=0.4)\n",
    "        ow = self.opt_stats\n",
    "        ax.scatter([ow[\"Volatility\"]], [ow[\"Return\"]], marker=\"*\", s=180)\n",
    "        if reg_data is not None:\n",
    "            ax.plot(reg_data[\"Volatility\"], reg_data[\"Return\"], linewidth=2)\n",
    "        ax.set_xlabel(\"σ (Volatility)\")\n",
    "        ax.set_ylabel(\"E(R) (Annual Return)\")\n",
    "        ax.set_title(\"Efficient Frontier (Monte Carlo)\")\n",
    "        fig.tight_layout()\n",
    "        path = None\n",
    "        if save:\n",
    "            path = os.path.join(self.output_dir, \"efficient_frontier.png\")\n",
    "            fig.savefig(path, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline\n",
    "proj = EfficientFrontierProject(TICKERS, START_DATE, END_DATE, rf=RISK_FREE_RATE, output_dir=OUTPUT_DIR)\n",
    "data_source = proj.fetch_prices()\n",
    "mu, Sigma, corr = proj.compute_statistics()\n",
    "mc_df, opt_w, opt_stats = proj.monte_carlo(n_portfolios=50000)\n",
    "model, reg_data = proj.regression_frontier(bins=60, degree=2)\n",
    "\n",
    "# Save artifacts\n",
    "corr_path = proj.plot_correlation_matrix(save=True)\n",
    "frontier_path = proj.plot_frontier(reg_data=reg_data, save=True)\n",
    "\n",
    "# Save CSV of optimal weights and a brief report\n",
    "s = pd.Series(opt_w, index=TICKERS, name=\"Weight\")\n",
    "dfw = pd.DataFrame(s)\n",
    "dfw.loc[\"Return\",\"Weight\"] = opt_stats[\"Return\"]\n",
    "dfw.loc[\"Volatility\",\"Weight\"] = opt_stats[\"Volatility\"]\n",
    "dfw.loc[\"Sharpe\",\"Weight\"] = opt_stats[\"Sharpe\"]\n",
    "dfw.to_csv(os.path.join(OUTPUT_DIR, \"optimal_weights.csv\"))\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, \"notebook_report.txt\"), \"w\") as f:\n",
    "    f.write(f\"Data source: {data_source}\\n\")\n",
    "    f.write(f\"Optimal portfolio: Return={opt_stats['Return']:.4f}, Vol={opt_stats['Volatility']:.4f}, Sharpe={opt_stats['Sharpe']:.3f}\\n\")\n",
    "    f.write(\"Outputs saved: correlation_matrix.png, efficient_frontier.png, optimal_weights.csv\\n\")\n",
    "\n",
    "# Display quick previews\n",
    "mu.to_frame(\"Annual E[R]\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c3dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key tables for review (these will render in Jupyter)\n",
    "from caas_jupyter_tools import display_dataframe_to_user\n",
    "display_dataframe_to_user(\"Annualized Mean Returns (E[R])\", mu.to_frame(\"Annual E[R]\"))\n",
    "display_dataframe_to_user(\"Annualized Covariance Matrix\", Sigma)\n",
    "display_dataframe_to_user(\"Correlation Matrix\", corr)\n",
    "display_dataframe_to_user(\"Monte Carlo Portfolios (sample)\", mc_df.sample(10, random_state=SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdc4d2a",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- If `yfinance` cannot  be download in your environment, the notebook **simulates** prices to demonstrate the pipeline.\n",
    "-"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
